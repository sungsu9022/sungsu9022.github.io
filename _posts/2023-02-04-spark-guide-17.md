---
title: "[스파크 완벽 가이드] 17. 스파크 배포 환경"
author: sungsu park
date: 2023-02-04 19:53:00 +0800
categories: [DevLog, Spark]
tags: [Spark]

---


# [스파크 완벽 가이드] 17. 스파크 배포 환경
> 클러스터 배포 시 선택 사항
> 스파크가 지원하는 클러스터 매니저
> 배포시 고려사항과 배포 환경 설정

## 17.1 스파크 앱 실행을 위한 클러스터 환경
- 클러스터를 구성할 수 있는 환경은 크게 2가지로 나눌수 있다.

### 17.1.1 설치형 클러스터 배포 환경
- 자체 데이터 센터를 운영하는 조직에 배포 환경에 적합한 배포환경이다.
  - 그 밖의 모든 상황에서 트레이드가 존재함.

#### 장점
- 하드웨어를 완전히 제어할 수 있으므로 특정 워크로드의 성능을 최적화 할수 있다.

#### 단점
- 설치형 클러스터의 크기가 제한적인데, 분석  워크로드에 필요한 자원은 상황에 따라 달라질수 있다.
  - 너무 작게 만들면 리소스가 많이 자는 작업을 할수 없고, 너무 크게 만들면 자원낭비가 심해진다.
- HDFS나 분산 키-값 저장소같은 자체 저장소 시스템을 선택하고 운영해야 한다.
- 상황에 따라 지리적 복제, 재해 복구 쳬계도 함께 구축/고민되어야 한다.

#### 구성시 유의사항
- 클러스터 매니저를 사용해서 자원 활용 문제를 해결해야 한다.



### 17.1.2 공개 클라우드
- 초기 빅데이터 시스템은 설치형 클러스터에 적합하게 설계되었으나 시간이 지날수록 클라우드 환경이 일반적인 스파크 운영 환경으로 자리잡고 있다.

#### 장점
- 자원을 탄력적으로 늘리고 줄이는것이 가능하다.
  - 필요에 따라 비용만 지불하고 반납하면 그만이다.
- 공개 클라우드 환경이 비용이 저렴하고 지리적 복제 기능을 지원하는 경우도 많이 있다.

#### 단점
- 설치형에서 클라우드로 이관하는 경우 기존 방식으로 실행하는것은 좋지 않을수 있음.
  - 아마존 S3, 애저 Blob, 구글 클라우드 저장소 등을 사용하는 방식으로 이관이 필요하다.
- 설칠형 구축 클러스터에 비해 세밀하게 컨트롤하지 못하는 부분이 있을수 있음.

## 17.2 클러스터 매니저
- 클라우드 환경에서 매니지드 서비스로 이용하는것이 아니라면 별도의 클러스터 매니저를 선택해야 한다.

### 17.2.1 스탠드얼론 모드
- 스파크의 스탠드얼론 클러스터 매니저는 매니저는 아파치 스파크 워크로드용으로 특별히 제작된 경량화 플랫폼이다.
- 다른 클러스터 매니저보다 제한적인 기능을 가지고 있다.
  - 스파크 애플리케이션에서만 실행할 수 있다.

#### 스탠드얼론 클러스터 시작하기
``` sh
// 마스터 프로세스 실행
$SPARK- HOME/sbin/start.master.sh

// 워커노드 프로세스 실행
$SPARK_HOME/sbin/start.slave.sh <마스터-스파크-프로세스-URI>
```

#### 스크립트를 이용한 스탠드얼론 클러스터 시작하기
- 시작 스크립트를 설정해 스탠드얼론 클러스터의 시작을 자동화할 수 있다.
- `start-all.sh`, `stop-master.sh`, `stop-slaves.sh`, `stop-all.sh` 등을 제공한다.

#### 스탠드얼론 클러스터 설정
- 앱 튜닝에 필요한 여러 가지 설정을 가지고 있다.
- 이러한 설정은 종료된 앱의 워커별작업 파일에서부터 워커의 코어와 메모리 등 모든것을  제어할 수 있다.

#### 애플리케이션 제출하기
- 마스터 프로세스의 URI를 이용해  `spark-submit` 명령을 사용할 수 있는 머신에서 애플리케이션을 제출할 수 있다.


### 17.2.2 YARN에서 스파크 실행하기
- 하둡 YARN은 잡 스케줄링과 클러스터 자원 관리용 프레임워크이다.
- 스파크는 기본적으로 하둡 YARN 클러스터 매니저를 지원하기는 하지만 하둡 자체가 필요한것은 아니다.
  - 스파크와 하둡은 직접적으로는 거의 관련이 없다.
- YARN은 다양한 실행 프레임워크를 지원하는 통합 스케줄러로, 스탠드언론 모드에 비해 많은 기능을 사용할 수 있다.

#### 애플리케이션 제출하기
- `--master` 인수 값을 `yarn`으로 지정하는 차이점이 있다.

### 17.2.3 YARN환경의 스파크 애플리케이션 설정하기
- YARN에 스파크 애플리케이션을 배포하려면 다양한 설정과 스파크 앱에 미치는 영향을 이해해야 한다.

#### 하둡 설정
- 스파크를 이용해 HDFS의 파일을 읽고 쓸며ㅕㄴ 스파크 클래스패스에 두개의 하둡 설정 파일을 포함시켜야 한다.
  - `hdfs-site.xml` : HDFS 클라이언트 동작 방식 결정
  - `core-site.xml` : 기본 파일 시스템의 이름을 설정
- 스파크에서 하둡 설정 파일을 사용하려면 `$SPARK_HOME/spark-env.sh` 파일의 `HADOOP_CONF_DIR` 변숫값을 하둡 설정 파일 경로로 지정하거나 `spark-submit` 명령을 사용해서 환경변수를 지정해야 한다.

### 17.2.4 메소스에서 스파크 실행하기
- 메소스는 스파크를 실행할 수 있는 또 다른 클러스터 매니저이다.
- 여러 스파크 개발자들이 개발한 오픈소스

#### 메소스 정의
- CPU, 메모리, 저장소, 그리고 다른 연산 자원을 머신에서 추상화한다.
- 이를 통해 내고장성(fault-tolerant) 및 탄력적 분산 시스템을 쉽게 구성하고 효과적으로 실행할 수 있다.

#### 메소스 특징
- 가장 무거운 클러스터 매니저이므로, 대규모의 메소스 배포 환경이 있는 경우에만 사용하는 것이 좋다.
- 거대한 인프라 구조이고, 메소스 클러스터를 배포하고 유지하는 방법을 별도 숙지하여야 한다.

#### 애플리케이션 제출하기
- 다른 클러스터 매니저와 유사한 방식으로 메소스 클러스터에 스파크 앱을 제출할 수 있다.
- `spark-env.sh`에 환경변수를 선언하고 사용할 수 있다.

``` sh
export MESOS_NATIVE_JAVA_LIBRARY=<libmesos.so 파일의 경로>
export SPARK_EXECUTOR_URI=<업로드한 spark-2.2.0.tar.gz 파얼의 URL>
```

``` scala
import org.apache.spark.sql.SparkSession
val spark = SparkSession.builder
  .master("mesos://HOST:5050")
  .appName("my app")
  .config("spark.executor.uri", "<path to spark-2.2.0.tar.gz uploaded above>")
  .getOrCreate()
```

#### 메소스 설정하기
- 실행과 관련된 설정을 제공한다. 자세한 내용은 공식 문서를 ㅊ마고

### 17.2.5 보안 관련 설정
- 스파크는 신뢰도가 낮은 환경에서 애플리케이션을 안전하게 실행할 수 있도록 저수준 API 기능을 제공한다.
- 인증, 네트워크 구간 암호화, TLS/SSL을 설정할 수 있다.

### 17.2.6 클러스터 네트워크 설정
- 더 나은 네트워크 실행 환경을 위해 시도할수 있는 튜닝 방법이다.
- 클러스터 노드 사이에 proxy를 사용하기 위해 스파크 클러스터에 사용자 정의 배포 설정을 적용하는 경우가 있을수 있다.

### 17.2.7 애플리케이션 스케줄링
- 연산 과정에서 필요한 자원을 스케줄링 할 수 있는 몇가지 기능을 제공한다.
- 첫째, 각 스파크 애플리케이션은 독립적인 익스큐터 프로세스를 실행한다.
  - 클러스터 매니저는 앱 전체에 대한 스케줄링 기능을 제공한다.
- 둘쨰, 스파크 앱에서 여러개의 잡을 다른 스레드가 제출한 경우 동시에 실행할 수 있다.

#### 동적 할당
- 하나의 클러스터에서 여러 스파크 앱을 실행하려면 워크로드에 따라 앱이 점유하는 자원을 동적으로 조정해야 한다.
- 동적 할당은 사용자 앱이 사용하지 않는 자원을 클러스터에 반환하고 필요할 때 다시 요청하는 방식을 의미한다.


## 17.3 기타 고려사항
- 애플리케이션 개수와 유형을 고려해야 한다.
- YARN은 HDFS를 사용하는 앱을 실행할 때 가장 적합하지만 그외의 경우에는 잘 사용하지 않는다.
  - YARN은 HDFS의 정보를 사용하도록 설계되어 있으므로 클라우드 환경을 제대로 지원할 수 없다.
  - 또 연산용 클러스터와 저장소 클러스터가 강하게 결합되어 있다.(클러스터 확장시 동시 확장만 가능)
- 메소스는 YARN이 가진 개념을 조금 더 개선하였으며 다양한 앱 유형을 지원한다.
  - 다만, 큰 규모의 클러스터에 적합하다.
  - 스파크 앱을 실행한다고 해서 메소스 클러스터를 꼭 구축해야 하는것은 안디ㅏ.
- 다양한 스파크 버전을 관리하는 것도 상당히 어려운 문제이다.
  -  다양한 스파크 버전으로 된 앱을 실행하려면 버전별 설정 스크립트를 관리하는 데 많은 시간을 할애해야 한다.
- 클러스터 매니저와 관계 없이 앱 디버깅이나 이슈 추적을 위한 로그를 기록하는 방식도 적절히 결정해야 한다.
- 데이터 카탈로그같은 저장된 데이터셋의 메타데이터 관리를 위한 메타스토어 사용을 고려해야 한다.
- 워크로드 특성에 맞춰 외부 셔플 서비스를 사용해야 할수도 있다.
- 클러스터에서 실행되는 스파크 잡을 디버깅하려면 최소한 기본적인 모니터링 솔루션 도입은 필수적이다.



## Reference
- [Spark 완벽 가이드](https://www.coupang.com/vp/products/164359777?itemId=471497435&vendorItemId=4215695264&src=1042503&spec=10304982&addtag=400&ctag=164359777&lptag=10304982I471497435&itime=20221030164504&pageType=PRODUCT&pageValue=164359777&wPcid=16589055075836517214634&wRef=&wTime=20221030164504&redirect=landing&gclid=Cj0KCQjwwfiaBhC7ARIsAGvcPe7kxytxjJU9Ylxpe5l8Jk9zhXhknDFceRzD80Zn6IzxUaF-RPn5OKAaAnGxEALw_wcB&campaignid=18626086777&adgroupid=)
