---
title: "[엘라스틱서치 바이블] 4. 데이터 다루기 -2(집계)"
author: sungsu park
date: 2023-12-24 20:19:00 +0800
categories: [DevLog, Elasticsearch]
tags: [Elasticsearch]

---


# 4. 데이터 다루기 -2

## 4.4 집계
- ES는 검색을 수행한 뒤에 그 결과를 집계(aggregation)하는 다양한 방법을 제공한다.

### 4.4.1 집계 기본
- 집계는 검색의 연장선
- 집계의 대상ㅇ을 추려낼 검색 조건을 검색 API에 담은 뒤 집계 조건을 추가해서 호출한다.

#### sum

```
### sum
GET /kibana_sample_data_ecommerce/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "term": {
      "currency" : {
        "value": "EUR"
      }
    }
  },
  "aggs": {
    "my-sum-aggregation-name": {
      "sum" : {
        "field":"taxless_total_price"
      }
    }
  }
}
```

``` json
{
  "took": 26,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 4675,
	  "relation": "eq"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"my-sum-aggregation-name": {
	  "value": 350884.12890625
	}
  }
}
```
- search API 요청 body에 "aggs"만 추가하고, size을 0으로 지정한 것을 확인할 수 있다.

#### 집계 요청시 주의사항
- size을 0으로 지정하면 검색에 상위 매칭된 문서가 무엇인지 받아볼 수 없다.
  - 매칭된 문서와 관계 없이 조건에 매치되는 모든 문서에 대한 집계 작업을 할 수 있다.
  - 집계 요청에서는 매칭 문서를 볼 니즈가 없으므로 대부분 집계 요청에서는 size를 0으로 지정하는 것이 이득이다.
- 요청 한번에 여러 집계를 요청할 수 있다.
  - 집계를 구분할 수 있는 이름을 붙여준다.(`my-sum-aggregation-name`)
- 집계 작업은 검색 쿼리에 매칭된 모든 문서에 대해 수행하므로 과도한 양을 대상으로 집계를 수행할 경우 전체 클러스터 성능에 영향을 줄수 있다.
  - 키바나 대시보드같은 시각화도구에서도 발생할 수 있음.
  - 통제되지 않은 사용자가 집계를 할 수 없도록 해야 한다.

### 4.4.2 메트릭 집계
- 문서에 대한 산술적인 연산을 수행한다.

#### avg, max, min, sum 집계
- 평균, 최대값, 최소값, 합계 등을 집계할 수 있다.

```
### avg
GET /kibana_sample_data_ecommerce/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "term": {
      "currency" : {
        "value": "EUR"
      }
    }
  },
  "aggs": {
    "my-avg-aggregation-name": {
      "avg" : {
        "field":"taxless_total_price"
      }
    }
  }
}
```

#### stats 집계
- 지정한 필드의 평균, 최댓값, 최솟값, 합, 개수를 모두 계산해서 반환한다.

```
### stats
GET /kibana_sample_data_ecommerce/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "term": {
      "currency" : {
        "value": "EUR"
      }
    }
  },
  "aggs": {
    "my-stats-aggregation-name": {
      "stats" : {
        "field":"taxless_total_price"
      }
    }
  }
}
```

``` json
{
  "took": 10,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 4675,
	  "relation": "eq"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"my-stats-aggregation-name": {
	  "count": 4675,
	  "min": 6.98828125,
	  "max": 2250.0,
	  "avg": 75.05542864304813,
	  "sum": 350884.12890625
	}
  }
}
```

- 위와 같이 여러 숫자 값을 한꺼번에 반환하는 메트릭 집계를 다중 값 숫자 메트릭 집계(multi-value numeric metric aggregation)이라 한다.

#### cardinality 집계
- cardinality 집계는 지정한 필드가 가진 고유한 값의 개수를 계산해 반환한다.
  - 이 값은 HyperLogLog++ 알고리즘을 사용해 추정한 근사값이다.

```
### cardinality
GET /kibana_sample_data_ecommerce/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "term": {
      "currency" : {
        "value": "EUR"
      }
    }
  },
  "aggs": {
    "my-cardinality-aggregation-name": {
      "cardinality" : {
        "field":"customer_id",
        "precision_threshold": 3000
      }
    }
  }
}
```

- precision_threshold 옵션은 정확도를 조절하기 위해 사용된다.
  - 정확도와 메모리 사용량에 비례한다.
  - 정확도를 올리기 위해 무작정 많이 높힐 필요가 없고, 최종 cardinality보다 높다면 정확도는 충분하다.
  - 기본값은 3000이고, 최댓값은 40000이다.

#### HyperLogLog++ 알고리즘
> [HyperLogLog Naver D2 레퍼런스](https://d2.naver.com/helloworld/711301)

- HyperLogLog의 핵심 아이디어는 정수의 상위 비트에 대한 확률적인 접근에서부터 시작한다.
- 어떤 정수가 있을 때 상위 첫 번째 비트가 0인 정수 또는 상위 첫 번째 비트가 1인 정수는 각각 전체 표현 가능한 정수 중 50%를 차지한다.
- 마찬가지로 상위 비트가 00, 01, 10, 11로 시작하는 정수 각각에 대한 최대 cardinality는 전체 표현 가능한 정수의 25%가 된다.
- HyperLogLog에서는 이렇게 상위 몇 비트(b)를 사용할 것인지에 따라 레지스터의 개수(m=2b)가 결정된다.
- 그리고 레지스터별 최대 cardinality는 '전체 표현 가능 정수 개수' ×개이다.(레지스터 개수를 늘이면 좀 더 정해에 가까운 추정 값을 계산할 수 있음)
- hashSet 대비 오차는 있으나 매우 효율적으로 근사값을 구할수 있음.

<img width="878" alt="" src="https://github.com/sungsu9022/study/assets/6982740/5c432f30-3a23-4ae1-98a1-b9b0186d3975">

### 4.4.3 버킷 집계
- 버킷 집계는 문서를 특정 기준으로 쪼개어 여러 부분 집합으로 나눈다.
- 이 부분 집합을 버킷이라고 하고, 각 버킷에 포함된 문서를 대상으로 별도의 하위 집계(sub-aggregation)을 수행하여 집계하는 방식이다.

#### range 집계
- 지정된 필드값을 기준으,로 문서를 원하는 버킷 구간으로 쪼개서 집계한다.
- 버킷 구간을 나눌 기준이 될 필드와 기준값을 지정해 요청한다.

```
### range
GET /kibana_sample_data_flights/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "distnace-kilometers-range": {
      "range" : {
        "field":"DistanceKilometers",
        "ranges": [
          {
            "to": 5000
          },
          {
            "from": 5000,
            "to": 10000
          },
          {
            "to": 10000
          }
        ]
      },
      "aggs": {
        "average-ticket-price": {
          "avg": {
            "field": "AvgTicketPrice"
          }
        }
      }
    }
  }
}
```

``` json
{
  "took": 86,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 10000,
	  "relation": "gte"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"distnace-kilometers-range": {
	  "buckets": [
		{
		  "key": "*-5000.0",
		  "to": 5000.0,
		  "doc_count": 4039,
		  "average-ticket-price": {
			"value": 513.3039915741715
		  }
		},
		{
		  "key": "*-10000.0",
		  "to": 10000.0,
		  "doc_count": 10060,
		  "average-ticket-price": {
			"value": 611.5759058298221
		  }
		},
		{
		  "key": "5000.0-10000.0",
		  "from": 5000.0,
		  "to": 10000.0,
		  "doc_count": 6021,
		  "average-ticket-price": {
			"value": 677.4985535093724
		  }
		}
	  ]
	}
  }
}
```

- 요청 body을 보면 range 밑에 "aggs"가 하나 더 있는데, 이 부분이 하위 집계이다.
- 위 요청 내용을 보면 DistanceKilometers 값을 기준으로 3개의 버킷을 쪼개고 아 내부에서 AvgTicketPrice avg 값을 집계한것을 알 수 있다.
- 하위 집계에 또 버킷 집계를 넣으면 다시 그 하위 집계를 지정하는 것도 가능하다.
  - 다만, 하위 집계의 깊이가 너무 깊어지면 성능에 심각한 문제가 생길수 있으니 지양해야 한다.

#### data_range 집계
- range 집계와 유사하나 date 타입 필드를 대상으로 사용하는 점과 from, to에 간단한 날짜 시간 계산식을 사용할수 있다는 차이가 있다.

```
### date_range
GET /kibana_sample_data_ecommerce/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "distnace-kilometers-range": {
      "date_range" : {
        "field":"order_date",
        "ranges": [
          {
            "to": "now-10d/d"
          },
          {
            "from": "now-10d/d",
            "to": "now"
          },
          {
            "to": "now"
          }
        ]
      }
    }
  }
}
```

- 위 요청에서 주목할 부분은 now를 사용한 점인데, now가 포함된 집계 요청은 캐시되지 않는다.(호출 시점마다 now 값이 다르기 떄문)
- 새로운 데이터가 들어와서 인덱스의 상태가 달라져도 샤드 요청 캐시는 무효화된다.

#### histogram 집계
- 지정한 필드의 값을 기준으로 버킷을 나눈다는 점에서 range 집계와 유사하다.
- 다른 점은 버킷 구분의 경계 기준값을 직접 지정하는 것이 아니라 버킷의 간격을 지정해서 집계를 나눈다는 점이다.

```
GET /kibana_sample_data_flights/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "my-histogram": {
      "histogram" : {
        "field":"DistanceKilometers",
        "interval": 1000
      }
    }
  }
}
```

``` json
{
  "took": 22,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 10000,
	  "relation": "gte"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"my-histogram": {
	  "buckets": [
		{
		  "key": 0.0,
		  "doc_count": 1799
		},
		{
		  "key": 1000.0,
		  "doc_count": 1148
		},
		{
		  "key": 2000.0,
		  "doc_count": 529
		},
		{
		  "key": 3000.0,
		  "doc_count": 241
		},
		{
		  "key": 4000.0,
		  "doc_count": 322
		},
		{
		  "key": 5000.0,
		  "doc_count": 411
		},
		{
		  "key": 6000.0,
		  "doc_count": 1062
		},
		{
		  "key": 7000.0,
		  "doc_count": 1718
		},
		{
		  "key": 8000.0,
		  "doc_count": 1343
		},
		{
		  "key": 9000.0,
		  "doc_count": 1487
		},
		{
		  "key": 10000.0,
		  "doc_count": 647
		},
		{
		  "key": 11000.0,
		  "doc_count": 653
		},
		{
		  "key": 12000.0,
		  "doc_count": 323
		},
		{
		  "key": 13000.0,
		  "doc_count": 302
		},
		{
		  "key": 14000.0,
		  "doc_count": 278
		},
		{
		  "key": 15000.0,
		  "doc_count": 282
		},
		{
		  "key": 16000.0,
		  "doc_count": 327
		},
		{
		  "key": 17000.0,
		  "doc_count": 41
		},
		{
		  "key": 18000.0,
		  "doc_count": 69
		},
		{
		  "key": 19000.0,
		  "doc_count": 32
		}
	  ]
	}
  }
}
```

- 위처럼 `interval`을 지정하면 해당 필드의 최솟값과 최댓값을 확인한 후 그 사이를 지정한 `interval`에 지정한 간격으로 쪼개서 버킷을 나눈다.
- 위치를 조정하고 싶은 경우 `offset`을 지정하여 사용할 수 있다.

```
### histogram + offset
GET /kibana_sample_data_flights/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "my-histogram": {
      "histogram" : {
        "field":"DistanceKilometers",
        "interval": 1000,
        "offset": 50
      }
    }
  }
}
```

- offset을 지정하지 않는 경우 `[0, 1000], [1000-2000], ...`로 구간이 생성되고, offset 50으로 지정한 경우 `[50 1050], [1050, 2050], ...`으로 구간이 생성되었다.
- 이 밖에도 min_doc_coun를 지정해서  버킷 내 문서 개수가 일정 이하인 버킷은 결과에서 제외할 수 있다.

#### data_histogram 집계

```
### date_histogram
GET /kibana_sample_data_ecommerce/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "my-date-histogram": {
      "date_histogram" : {
        "field":"order_date",
        "calendar_interval": "month"
      }
    }
  }
}
```

``` json
{
  "took": 34,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 4675,
	  "relation": "eq"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"my-date-histogram": {
	  "buckets": [
		{
		  "key_as_string": "2023-12-01T00:00:00.000Z",
		  "key": 1701388800000,
		  "doc_count": 3751
		},
		{
		  "key_as_string": "2024-01-01T00:00:00.000Z",
		  "key": 1704067200000,
		  "doc_count": 924
		}
	  ]
	}
  }
}
```

- 위처럼 날짜 기준으로 집계를 할수 있다.

#### calendar_interval
> 12h 같은 단위값은 지정할 수 없음.

- minute 또는 1m : 분단위
- hour 또는 1h : 시간 단위
- day 또는 1d : 일 단위
- month 또는 1M : 월 단위
- quarter 또는 1q : 분기 단위
- year 또는 1y : 연 단위

#### fixed_interval
-  calendar_interval에서는 12h 같은 값을 지정할 수 없으나 fixed_interval에서는 지정이 가능하다.
- ex. `"fixed_interval": "3h"`로 지정하면 3시간 간격으로 버킷 구간을 쪼갤 수 있다.


#### terms 집계
- 필드에 대해 가장 빈도수가 높은 term 순서대로 버킷을 생성한다.
- 최대 몇개의 버킷을 생성할것인지 size로 지정한다.

```
### terms 집계
GET /kibana_sample_data_logs/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "my-terms-aggs": {
      "terms" : {
        "field":"host.keyword",
        "size": "10"
      }
    }
  }
}
```

``` json
{
  "took": 27,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 10000,
	  "relation": "gte"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"my-terms-aggs": {
	  "doc_count_error_upper_bound": 0,
	  "sum_other_doc_count": 0,
	  "buckets": [
		{
		  "key": "artifacts.elastic.co",
		  "doc_count": 6488
		},
		{
		  "key": "www.elastic.co",
		  "doc_count": 4779
		},
		{
		  "key": "cdn.elastic-elastic-elastic.org",
		  "doc_count": 2255
		},
		{
		  "key": "elastic-elastic-elastic.org",
		  "doc_count": 552
		}
	  ]
	}
  }
}
```

- 각 샤드에서 size 개수만큼 term을 뽑아 빈도수를 센다.
- 각 샤드에서 수행된 계산을 한곳으로 모아 합산한 후 size개수만큼 버킷을 뽑는다.
  - size 개수와 각 문서의 분포에 따라 결과가 정확하지 않을 수 있음.( term의 개수가 2개인데 size를 10개로 한다고한들 10개를 만들수 없다.)


#### doc_count_error_upper_bound
- doc_count의 오차 상한선을 나타낸다.
- 이 값이 크다면 size를 높이는 것을 고려할 수 있다.
- 정확도가 올라가는 만큼 성능은 하락할 수 있다.

#### sum_other_doc_count
- 최종적으로 버킷에 포함되지 않은 문서 수
- 상위 term에 들지 못한 문서 개수의 총합이다.


#### composite 집계
- 모든 term에 대해서 페이지네이션으로 전부 순회하면서 집계하려는 경우 사용(term에서는 정확하지 않을수 있기에)
- sources로 지정된 하위 집계의 버킷 전부를 페이지네이션을 이용해서 효율적으로 순회하는 집계다.
- 또한 soruces에 하위 집계를 여러 개 지정한 뒤 조합된 버킷을 생성할 수 있다.

```
### composite 집계
GET /kibana_sample_data_logs/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "composite-aggs": {
      "composite" : {
        "size": 100,
        "sources": [
          {
            "terms-aggs": {
              "terms": {
                "field": "host.keyword"
              }
            }
          },
          {
            "date-histogram-aggs": {
              "date_histogram": {
                "field": "@timestamp",
                "calendar_interval": "day"
              }
            }
          }
        ]
      }
    }
  }
}
```

``` json
{
  "took": 79,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 10000,
	  "relation": "gte"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"composite-aggs": {
	  "after_key": {
		"terms-aggs": "cdn.elastic-elastic-elastic.org",
		"date-histogram-aggs": 1706054400000
	  },
	  "buckets": [
		{
		  "key": {
			"terms-aggs": "artifacts.elastic.co",
			"date-histogram-aggs": 1702771200000
		  },
		  "doc_count": 124
		},
		{
		  "key": {
			"terms-aggs": "artifacts.elastic.co",
			"date-histogram-aggs": 1702857600000
		  },
		  "doc_count": 88
		},
                ....
	  ]
	}
  }
}
```

- composite 아래의 size는 페이지네이션 한 번에 몇 개의 버킷을 반환할 것인가를 지정한다.
- sources에는 버킷을 조합하여 순회할 하위 집계를 지정한다.
- 하위 집계는 terms, histogram, date_histogratm 집계 등 일부 집계만 지정할 수 있다.
  - [ES Composite Aggregation Doc](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-composite-aggregation.html)
- 응답의 버킷 key가 여러 집계의 결과로 조합된 것을 확인할 수 있다.
  -  terms-aggs, date-histogram-aggs의 조합을 기준으로 집계됨.

#### composite.after
- 집계 결과의 다음 페이지를 보고싶다면 composite 하위에 after을 추가하여 조회할수 있다.

```
### composite 집계 after
GET /kibana_sample_data_logs/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "composite-aggs": {
      "composite" : {
        "size": 100,
        "sources": [
          {
            "terms-aggs": {
              "terms": {
                "field": "host.keyword"
              }
            }
          },
          {
            "date-histogram-aggs": {
              "date_histogram": {
                "field": "@timestamp",
                "calendar_interval": "day"
              }
            }
          }
        ],
        "after": {
          "terms-aggs": "cdn.elastic-elastic-elastic.org",
          "date-histogram-aggs": 1675209600000
        }
      }
    }
  }
}
```

### 4.4.4 파이프라인 집계
- 파이프라인 집계는 문서나 필드의 내용이 아니라 다른 집계 결과를 집계 대상으로 한다.
- 주로 buckets_path라는 인자를 통해 다른 집계의 결과를 가져오고, 이 buckets_path는 상대 경로로 지정한다.

#### buckets_path 지정 구문
- `>` : 하위 집계로 이동하는 구분자
- `.` : 하위 메트릭으로 이동하는 구분자
- 집계 이름
- 메트릭 이름

#### cumulative_sum 집계
- 다른 집계 값을 누적하여 합산한다.

```
### cumulative_sum 집계
GET /kibana_sample_data_ecommerce/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "daily-timestamp-bucket": {
      "date_histogram" : {
      "field": "order_date",
      "calendar_interval": "day"
      },
      "aggs": {
        "daily-total-quantity-average": {
          "avg": {
            "field": "total_quantity"
          }
        },
        "pipeline-sum": {
          "cumulative_sum": {
            "buckets_path": "daily-total-quantity-average"
          }
        }
      }
    }
  }
}
```

``` json
{
  "took": 30,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 4675,
	  "relation": "eq"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"daily-timestamp-bucket": {
	  "buckets": [
		{
		  "key_as_string": "2023-12-07T00:00:00.000Z",
		  "key": 1701907200000,
		  "doc_count": 146,
		  "daily-total-quantity-average": {
			"value": 2.1780821917808217
		  },
		  "pipeline-sum": {
			"value": 2.1780821917808217
		  }
		},
                ....
		{
		  "key_as_string": "2024-01-05T00:00:00.000Z",
		  "key": 1704412800000,
		  "doc_count": 152,
		  "daily-total-quantity-average": {
			"value": 2.289473684210526
		  },
		  "pipeline-sum": {
			"value": 64.71700410498919
		  }
		},
		{
		  "key_as_string": "2024-01-06T00:00:00.000Z",
		  "key": 1704499200000,
		  "doc_count": 142,
		  "daily-total-quantity-average": {
			"value": 2.183098591549296
		  },
		  "pipeline-sum": {
			"value": 66.90010269653848
		  }
		}
	  ]
	}
  }
}
```

- 일 단위로 total_quantity의 평균을 구하기 위해 date_histogram으로 버킷을 나눈 뒤 하위 집계로 avg 집계를 지정했다.
- 그리고 date_histogram의 하위 집계로 cumulative_sum 집계를 추가 지정했다.


#### max_bucket 집계
- 다른 집계의 결과를 받아서 그 결과가 가장 큰 버킷의 key와 결과값을 구하는 집계이다.

```
### max_bucket 집계
GET /kibana_sample_data_ecommerce/_search
Host: localhost:9200
Content-Type: application/json

{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "daily-timestamp-bucket": {
      "date_histogram" : {
        "field": "order_date",
        "calendar_interval": "day"
      },
      "aggs": {
        "daily-total-quantity-average": {
          "avg": {
          "field": "total_quantity"
          }
        }
      }
    },
    "max-total-quantity": {
      "max_bucket": {
        "buckets_path": "daily-timestamp-bucket>daily-total-quantity-average"
      }
    }
  }
}
```

``` json
{
  "took": 6,
  "timed_out": false,
  "_shards": {
	"total": 1,
	"successful": 1,
	"skipped": 0,
	"failed": 0
  },
  "hits": {
	"total": {
	  "value": 4675,
	  "relation": "eq"
	},
	"max_score": null,
	"hits": []
  },
  "aggregations": {
	"daily-timestamp-bucket": {
	  "buckets": [
		{
		  "key_as_string": "2023-12-07T00:00:00.000Z",
		  "key": 1701907200000,
		  "doc_count": 146,
		  "daily-total-quantity-average": {
			"value": 2.1780821917808217
		  }
		},
                ....
		{
		  "key_as_string": "2024-01-05T00:00:00.000Z",
		  "key": 1704412800000,
		  "doc_count": 152,
		  "daily-total-quantity-average": {
			"value": 2.289473684210526
		  }
		},
		{
		  "key_as_string": "2024-01-06T00:00:00.000Z",
		  "key": 1704499200000,
		  "doc_count": 142,
		  "daily-total-quantity-average": {
			"value": 2.183098591549296
		  }
		}
	  ]
	},
	"max-total-quantity": {
	  "value": 2.289473684210526,
	  "keys": [
		"2024-01-05T00:00:00.000Z"
	  ]
	}
  }
}
```

- buckets_path가 절대경로가 아니라 상대경로 이므로 daily-timestamp-bucket에서 하위 집계인 daily-total-quantity-average로 이동하는 구분자를 사용했다.
  - `"buckets_path": "daily-timestamp-bucket>daily-total-quantity-average"`


## Reference
- [HyperLogLog Naver D2 레퍼런스](https://d2.naver.com/helloworld/711301)
- [ES Composite Aggregation Doc](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-composite-aggregation.html)
